{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Kaggle_ CNN_final.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rAyeycfUY7dU",
        "outputId": "0149d6a4-7c81-49cf-8e96-f32fae88ebd0"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BxZiRqZfZJDK"
      },
      "source": [
        "import os\n",
        "KAGGLE_HOME_DIR = '/content/drive/MyDrive/kaggle'\n",
        "os.environ['KAGGLE_HOME_DIR'] = KAGGLE_HOME_DIR"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w7JtlctKZJce",
        "outputId": "7e1f7d28-1720-4e13-84f1-c363e7ecd4b5"
      },
      "source": [
        "%cd {KAGGLE_HOME_DIR}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/kaggle\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AXxrpUz0ZJ63"
      },
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pickle\n",
        "import csv\n",
        "import time\n",
        "import torch\n",
        "import torchvision\n",
        "from sklearn import preprocessing\n",
        "from torchvision import transforms, datasets\n",
        "from tqdm import tqdm\n",
        "from tensorflow import keras\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import tensorflow as tf\n",
        "from keras.utils.vis_utils import plot_model\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv2D, Dropout, Flatten, MaxPooling2D,LeakyReLU\n",
        "from keras.utils.np_utils import to_categorical \n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D ,BatchNormalization,Activation\n",
        "from tensorflow.keras.optimizers import Adam ,RMSprop, SGD, Adagrad, Adamax\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, LearningRateScheduler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras import regularizers\n",
        "from keras.regularizers import l2\n",
        "from tensorflow.keras import layers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hskLMJRXZhFy"
      },
      "source": [
        "SUBMISSION_HEADER = ['Id', 'class']\n",
        "RANDOM_STATE = 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x8pEa0MJZjp1"
      },
      "source": [
        "def open_pickled_file(file):\n",
        "    with open(file, 'rb') as f:\n",
        "        data = pd.read_pickle(file)\n",
        "    return np.asarray(data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eQRiBQEDZm6b"
      },
      "source": [
        "def export_predictions(y_pred):\n",
        "    timestr = time.strftime(\"%Y%m%d-%H%M%S\")\n",
        "    filename = KAGGLE_HOME_DIR+'/prediction{}.csv'.format(timestr)\n",
        "    file = open(filename, 'w+', newline ='')\n",
        "    with file:    \n",
        "        writer = csv.writer(file)\n",
        "        writer.writerow(SUBMISSION_HEADER)\n",
        "        writer.writerows(enumerate(y_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nXJ7d1ajZpXT"
      },
      "source": [
        "def preprocess(X, y):\n",
        "    X = scale(X)\n",
        "    y = encode(y)\n",
        "    return X, y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xuu4ORhcZsST"
      },
      "source": [
        "def encode(y):\n",
        "    le = preprocessing.LabelEncoder()\n",
        "    le.fit(y)\n",
        "    return le.transform(y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QZnCQV2SZva1"
      },
      "source": [
        "def scale(X):\n",
        "    max_val = np.max(X)\n",
        "    return X/max_val"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LPXV9TOGZyjB"
      },
      "source": [
        "X_train_raw = open_pickled_file(KAGGLE_HOME_DIR+'/x_train.pkl.zip')\n",
        "y_train_raw = open_pickled_file(KAGGLE_HOME_DIR+'/y_train.pkl')\n",
        "X_test_raw = open_pickled_file(KAGGLE_HOME_DIR+'/x_test.pkl.zip')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BWeWIDLQuH2M"
      },
      "source": [
        "X_train, y_train = preprocess(X_train_raw, y_train_raw)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "js-BnrUW4oAo"
      },
      "source": [
        "X_test = X_test_raw/255"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3x9yL5emZ1Ko"
      },
      "source": [
        "Y_enc = to_categorical(y_train, 11)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_wGpWixHmPIr"
      },
      "source": [
        "X_train, X_val, y_train, y_val = train_test_split(X_train, Y_enc, test_size=0.2,random_state =0, stratify=Y_enc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dcYgn1sOmgVr"
      },
      "source": [
        "batch_size = 128\n",
        "epochs = 5\n",
        "num_classes = 11"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pt18gWWjmqnx"
      },
      "source": [
        "model = Sequential([\n",
        "# data_augmentation,\n",
        "layers.Conv2D(32, kernel_size=(3, 3),activation='linear',input_shape=(96,96,1),padding='same', kernel_regularizer=l2(0.01),\n",
        "    bias_regularizer=l2(0.01)),\n",
        "layers.LeakyReLU(alpha=0.1),\n",
        "layers.BatchNormalization(),\n",
        "layers.MaxPooling2D((2, 2),padding='same'),\n",
        "\n",
        "layers.Conv2D(64, (3, 3), activation='linear',padding='same'),\n",
        "layers.LeakyReLU(alpha=0.1),\n",
        "layers.BatchNormalization(),\n",
        "layers.MaxPooling2D(pool_size=(2, 2),padding='same'),\n",
        "\n",
        "layers.Conv2D(128, (3, 3), activation='linear',padding='same', kernel_regularizer=l2(0.01),\n",
        "    bias_regularizer=l2(0.01)),\n",
        "layers.LeakyReLU(alpha=0.1), \n",
        "layers.BatchNormalization(),         \n",
        "layers.MaxPooling2D(pool_size=(2, 2),padding='same'),\n",
        "\n",
        "layers.Conv2D(256, (3, 3), activation='linear',padding='same'),\n",
        "layers.LeakyReLU(alpha=0.1),\n",
        "layers.BatchNormalization(),                 \n",
        "layers.MaxPooling2D(pool_size=(2, 2),padding='same'),\n",
        "layers.Dropout(0.25),\n",
        "\n",
        "layers.Flatten(),\n",
        "\n",
        "layers.Dense(128, activation='linear'),\n",
        "layers.LeakyReLU(alpha=0.1),  \n",
        "layers.BatchNormalization(),\n",
        "layers.Dropout(0.25),\n",
        "\n",
        "layers.Dense(64, activation='linear'),\n",
        "layers.LeakyReLU(alpha=0.1), \n",
        "layers.BatchNormalization(), \n",
        "layers.Dropout(0.25),\n",
        "\n",
        "layers.Dense(num_classes, activation='softmax')])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B_W4ESK8WmZT"
      },
      "source": [
        "model1 = Sequential([\n",
        "    layers.Conv2D(32, kernel_size = (3,3), activation='relu', input_shape = (96,96,1)),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Conv2D(32, kernel_size = (3,3), activation='relu'),\n",
        "    layers.BatchNormalization(),\n",
        "\n",
        "    # Add convolutional layer consisting of 32 filters and shape of 5x5 with ReLU activation\n",
        "    # We give strides=2 for space between each sample on the pixel grid\n",
        "    layers.Conv2D(32, kernel_size = (5,5), strides=2, padding='same', activation='relu'),\n",
        "    layers.BatchNormalization(),\n",
        "    # Dropping %40 of neurons\n",
        "    layers.Dropout(0.4),\n",
        "    layers.Conv2D(64, kernel_size = (3,3), activation='relu', padding='same'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Conv2D(64, kernel_size = (3,3), activation='relu', padding='same'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Conv2D(64, kernel_size = (5,5), strides=2, padding='same', activation='relu'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Dropout(0.4),\n",
        "\n",
        "    layers.Conv2D(128, kernel_size = 4, activation='relu'),\n",
        "    layers.BatchNormalization(),\n",
        "    # To be able to merge into fully connected layer we have to flatten\n",
        "    layers.Flatten(),\n",
        "    layers.Dropout(0.4),\n",
        "    layers.Dense(128, activation='relu'),\n",
        "    layers.Dense(256, activation='relu'),\n",
        "    # Lets add softmax activated neurons as much as number of classes\n",
        "    layers.Dense(num_classes, activation = \"softmax\")\n",
        "                     \n",
        "])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_master = Sequential([\n",
        "    layers.Conv2D(96, kernel_size=(3, 3), activation='relu', input_shape=(96,96,1), padding=\"same\"),\n",
        "    layers.Conv2D(96, kernel_size=(3, 3), activation='relu', padding = 'same'),\n",
        "    layers.Conv2D(96, (3, 3), activation='relu', padding = 'same'),\n",
        "    layers.MaxPooling2D(pool_size=(3, 3), strides = 2),\n",
        "    layers.Conv2D(192, (3, 3), activation='relu', padding = 'same'),\n",
        "    layers.Conv2D(192, (3, 3), activation='relu', padding = 'same'),\n",
        "    layers.Conv2D(192, (3, 3), activation='relu', padding = 'same'),\n",
        "    layers.MaxPooling2D(pool_size=(3, 3), strides = 2),\n",
        "    layers.Conv2D(192, (3, 3), activation='relu', padding = 'same'),\n",
        "    layers.Conv2D(192, (1, 1), activation='relu'),\n",
        "    layers.Conv2D(11, (1, 1)),\n",
        "    layers.GlobalAveragePooling2D(),\n",
        "    layers.Activation(activation='softmax')\n",
        "])\n",
        "    \n"
      ],
      "metadata": {
        "id": "O3Mf_5mYgoOm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PeDgh-IbZ5ZP"
      },
      "source": [
        "def data_augmentation(X, y):\n",
        "  img = ImageDataGenerator(\n",
        "      rotation_range = 5,\n",
        "      horizontal_flip= True,\n",
        "      zoom_range=0.02,\n",
        "      # rescale=1./255,\n",
        "      # shear_range=0.2,\n",
        "      width_shift_range=0.15, \n",
        "      height_shift_range = 0.15)\n",
        "  Train_batch = img.flow(X, y, batch_size = 32)\n",
        "  return Train_batch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MufqQnMq3Zi0"
      },
      "source": [
        "# def data_augmentation_valid(X, y):\n",
        "#   img = ImageDataGenerator(\n",
        "#       horizontal_flip = True\n",
        "#   )\n",
        "#   Train_batch = img.flow(X, y, batch_size = 32)\n",
        "#   return Train_batch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vT93jEI4aj3l"
      },
      "source": [
        "dataload = data_augmentation(X_train.reshape(-1,96,96,1),y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C5N3vVaO4OGM"
      },
      "source": [
        "dataloadval = data_augmentation(X_val.reshape(-1,96,96,1), y_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "akjpHOLzTHGc",
        "outputId": "b7d7d1fb-00fd-4db3-8c59-eef29ebeb405"
      },
      "source": [
        "tf.test.is_built_with_cuda()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "QaBfBMDbTJk6",
        "outputId": "6c4fa62d-29fd-44d8-a077-28ab39925362"
      },
      "source": [
        "tf.test.gpu_device_name()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/device:GPU:0'"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aVWEx9QQDF7n"
      },
      "source": [
        "# callbacks = [EarlyStopping(patience=3, restore_best_weights=True),\n",
        "#              ReduceLROnPlateau(patience=2),\n",
        "#              ModelCheckpoint(filepath=KAGGLE_HOME_DIR+'/ImageDataGen_Size256_oneHOT_ClassWeights_Callbacks_SGD_L2.h5', save_best_only=True)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zEZu-Fu6MSFt"
      },
      "source": [
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n",
        "                              patience=5, verbose=1)\n",
        "# lr_scheduler = LearningRateScheduler(scheduler)\n",
        "checkpoint = ModelCheckpoint(filepath=KAGGLE_HOME_DIR+'/best_model', monitor='val_accuracy', verbose=1, mode= 'max', save_best_only=True, save_weights_only=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1xG8dpfdnhob",
        "outputId": "0323a0e3-4071-4a22-ffd6-360b27f799d8"
      },
      "source": [
        "%%timeit -n1 -r1 \n",
        "with tf.device('/GPU:0'):\n",
        "  model.compile(loss=\"categorical_crossentropy\", optimizer= Adam(learning_rate=0.01), metrics=[\"accuracy\"])\n",
        "  # This model is overfitting\n",
        "  # model.fit(X_train, y_train, epochs=50, shuffle= True)\n",
        "  history = model.fit(dataload , validation_data=dataloadval, epochs=100, shuffle=True, batch_size=batch_size, callbacks=[reduce_lr, checkpoint])\n",
        "  # Plot history: accuracy\n",
        "  plt.plot(history.history['accuracy'])\n",
        "  plt.plot(history.history['val_accuracy'])\n",
        "  plt.title('model accuracy')\n",
        "  plt.ylabel('accuracy')\n",
        "  plt.xlabel('epoch')\n",
        "  plt.legend(['train', 'val'], loc='upper left')\n",
        "  plt.show()\n",
        "\n",
        "  # Plot history: loss\n",
        "  plt.plot(history.history['loss'])\n",
        "  plt.plot(history.history['val_loss'])\n",
        "  plt.title('model loss')\n",
        "  plt.ylabel('loss')\n",
        "  plt.xlabel('epoch')\n",
        "  plt.legend(['train', 'val'], loc='upper left')\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rDT1nD0lT73i",
        "outputId": "24c94fea-4698-40de-8fea-c60352afdf3a"
      },
      "source": [
        "model.load_weights(KAGGLE_HOME_DIR+'/best_model')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f67cd564650>"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U0jDpU-GzpZQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "794d1f98-e896-412d-9f3d-cf2fbd923ac1"
      },
      "source": [
        "model.evaluate(X_val,y_val)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "75/75 [==============================] - 1s 18ms/step - loss: 1.2124 - accuracy: 0.6627\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.2124394178390503, 0.6627417802810669]"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ghtuw2Je15UG"
      },
      "source": [
        "pred = model.predict(X_test)\n",
        "pred= np.argmax(pred, axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MMl7UqKv74WZ"
      },
      "source": [
        "export_predictions(pred)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}